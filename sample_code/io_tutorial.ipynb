{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#py4DSTEM-io\" data-toc-modified-id=\"py4DSTEM-io-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>py4DSTEM io</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Version-info\" data-toc-modified-id=\"Version-info-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Version info</a></span></li><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Set up</a></span></li><li><span><a href=\"#Non-native-files:-loading-4D-datacubes\" data-toc-modified-id=\"Non-native-files:-loading-4D-datacubes-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Non-native files: loading 4D datacubes</a></span></li><li><span><a href=\"#Native-HDF5-files:-browsing-and-loading-data\" data-toc-modified-id=\"Native-HDF5-files:-browsing-and-loading-data-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Native HDF5 files: browsing and loading data</a></span></li><li><span><a href=\"#The-DataObject-class\" data-toc-modified-id=\"The-DataObject-class-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>The <code>DataObject</code> class</a></span></li><li><span><a href=\"#Constructing-DataObject-instances\" data-toc-modified-id=\"Constructing-DataObject-instances-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>Constructing <code>DataObject</code> instances</a></span></li><li><span><a href=\"#Native-files:-save,-append,-copy\" data-toc-modified-id=\"Native-files:-save,-append,-copy-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>Native files: save, append, copy</a></span></li><li><span><a href=\"#Native-files:-remove,-overwrite,-repack\" data-toc-modified-id=\"Native-files:-remove,-overwrite,-repack-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>Native files: remove, overwrite, repack</a></span></li><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-1.0.10\"><span class=\"toc-item-num\">1.0.10&nbsp;&nbsp;</span>Metadata</a></span></li><li><span><a href=\"#topgroup-and-heirarchical-formatting:-.h5-files-containing-multiple-py4DSTEM-'files'\" data-toc-modified-id=\"topgroup-and-heirarchical-formatting:-.h5-files-containing-multiple-py4DSTEM-'files'-1.0.11\"><span class=\"toc-item-num\">1.0.11&nbsp;&nbsp;</span><code>topgroup</code> and heirarchical formatting: .h5 files containing multiple py4DSTEM 'files'</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py4DSTEM io\n",
    "\n",
    "This notebook discusses / demonstrates the read/write functionality of the py4DSTEM package.\n",
    "\n",
    "Use cases shown here include:\n",
    "- Non-native files: loading 4D datacubes (supported: .dm3/.dm4)\n",
    "- Native HDF5 files: browsing and loading data\n",
    "- Native files: save, append, copy\n",
    "- Native files: remove, overwrite, repack\n",
    "- Metadata: read, write, append\n",
    "- `topgroup` and heirarchical formatting: .h5 files containing multiple py4DSTEM 'files'\n",
    "\n",
    "### Data\n",
    "This notebooks creates a number of different test files.  They are all placed in a single directory which you'll need to specify.  To run this notebook locally, \n",
    "1. Create a directory to store this notebook's input and output files somewhere on your system. In the cell immediately below this one, set `dirpath` to point to this folder.\n",
    "2. Download the sample .dm file, and the sample .h5 file. They can be found [here](https://drive.google.com/file/d/1B-xX3F65JcWzAg0v7f1aVwnawPIfb5_o/view?usp=sharing) and [here](https://drive.google.com/file/d/12Q3T57x9N2vkyY0llqBLKn_0JPurQM6Y/view?usp=sharing).  Put both files in the directory you made.  In the cell below, make sure `filename_dm` and `filename_py4DSTEM_sample` specify the names of these two files.\n",
    "\n",
    "The experimental 4DSTEM data used in this notebook was collected by Steven Zeltmann.\n",
    "\n",
    "### Version info\n",
    "\n",
    "Last updated on 2019-11-25 with py4DSTEM version 0.11.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file and directory names\n",
    "dirpath = \"data/\"     # Please set this\n",
    "filename_dm = \"small4DSTEMscan_10x10.dm3\"                             # and this\n",
    "filename_py4DSTEM_sample = \"small4DSTEMscan_10x10.h5\"                 # and this\n",
    "filename_py4DSTEM_1 = \"py4DSTEM_iotest_1.h5\"\n",
    "filename_py4DSTEM_2 = \"py4DSTEM_iotest_2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import py4DSTEM\n",
    "from file_getter import download_file_from_google_drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath handling\n",
    "from pathlib import Path\n",
    "from os.path import exists\n",
    "from os import remove as rm, listdir\n",
    "\n",
    "dpath = Path(dirpath)\n",
    "filepath_dm = dpath/Path(filename_dm)\n",
    "filepath_py4DSTEM_sample = dpath/Path(filename_py4DSTEM_sample)\n",
    "filepath_py4DSTEM_1 = dpath/Path(filename_py4DSTEM_1)\n",
    "filepath_py4DSTEM_2 = dpath/Path(filename_py4DSTEM_2)\n",
    "\n",
    "if exists(filepath_dm):\n",
    "    pass\n",
    "else:\n",
    "    download_file_from_google_drive(id_='1B-xX3F65JcWzAg0v7f1aVwnawPIfb5_o' ,\n",
    "                                    destination=f'{filepath_dm}')\n",
    "if exists(filepath_py4DSTEM_sample):\n",
    "    pass\n",
    "else:\n",
    "    download_file_from_google_drive(id_='12Q3T57x9N2vkyY0llqBLKn_0JPurQM6Y',\n",
    "                                   destination=f'{filepath_py4DSTEM_sample}')\n",
    "    \n",
    "\n",
    "\n",
    "assert(exists(dpath)), \"The specified directory {} does not exist\".format(dpath)\n",
    "assert(exists(filepath_dm)), \"The specified .dm file {} does not exist\".format(filepath_dm)\n",
    "\n",
    "# Utility functions for clearing files\n",
    "def rm_file(fp):\n",
    "    if exists(fp):\n",
    "        rm(fp)\n",
    "rm_file(filepath_py4DSTEM_1)\n",
    "rm_file(filepath_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-native files: loading 4D datacubes\n",
    "from \n",
    "- .dm3/.dm4\n",
    "- numpy array\n",
    "- empad TK\n",
    "- medipix TK\n",
    "- 4DCAMERA TK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a .dm file\n",
    "datacube = py4DSTEM.io.read(filepath_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is an instance of the py4DSTEM DataCube class\n",
    "datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data\n",
    "datacube.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data shape after reading the file\n",
    "print(datacube.data.shape)\n",
    "print((datacube.R_Nx,datacube.R_Ny,datacube.Q_Nx,datacube.Q_Ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some files, the scan shape is not in the file metadata, and needs to be set manually\n",
    "datacube.set_scan_shape(10,10)\n",
    "print(datacube.data.shape)\n",
    "print((datacube.R_Nx,datacube.R_Ny,datacube.Q_Nx,datacube.Q_Ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary data visualization - the maximum diffraction pattern\n",
    "max_dp = np.max(datacube.data, axis=(0,1))\n",
    "py4DSTEM.visualize.show(max_dp,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you can get your 4D datacube into a numpy array,\n",
    "# you can create a DataCube directly\n",
    "data4d = np.ones((5,5,6,6))\n",
    "datacube_fromarray = py4DSTEM.io.DataCube(data=data4d)\n",
    "datacube_fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native HDF5 files: browsing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display file contents, without loading anything\n",
    "py4DSTEM.io.read(filepath_py4DSTEM_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print file version\n",
    "v = py4DSTEM.io.native.get_py4DSTEM_version(filepath_py4DSTEM_sample)\n",
    "print(\"written by py4DSTEM version {}.{}.{}\".format(v[0],v[1],v[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some named datablocks\n",
    "datacube = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='4ddatacube')\n",
    "max_dp = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='max_dp')\n",
    "three_dps = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='three_dps')\n",
    "BF_image = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='BF_image')\n",
    "some_bragg_disks = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='some_bragg_disks')\n",
    "braggdisks = py4DSTEM.io.read(filepath_py4DSTEM_sample, data_id='braggpeaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `DataObject` class\n",
    "py4DSTEM reads to and writes from chunks of data stored as instances of a class called `DataObject`.  `DataObject` has seven child classes: `DataCube`, `CountedDataCube`, `RealSlice`, `DiffractionSlice`, `PointList`, `PointListArray`, and `Metadata`.  The first six are discussed here.  Storing and retrieving metadata and the `Metadata` class are discussed later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataCubes are for 4D-STEM scans - they contain 2D grids of 2D diffraction patterns\n",
    "datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(isinstance(datacube,py4DSTEM.io.DataObject))\n",
    "assert(isinstance(datacube,py4DSTEM.io.DataCube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiffractionSlices and RealSlices\n",
    "# These are intended as containers for data that is 2D, either\n",
    "# in the shape of diffraction or real space.\n",
    "max_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dp.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show(max_dp.data,0,2,figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_image.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show(BF_image.data,contrast='minmax',figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They can also store 3D data, corresponding to stacks of 2D images\n",
    "three_dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dps.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show_image_grid(lambda i:three_dps.data[:,:,i],1,3,min=0.5,max=2,axsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointList\n",
    "some_bragg_disks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is essentially a wrapper / .h5 interface for numpy structured arrays [https://numpy.org/doc/stable/user/basics.rec.html]\n",
    "some_bragg_disks.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_bragg_disks.data['qx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointListArray\n",
    "braggdisks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These store a PointList at every scan position\n",
    "braggdisks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a PointList\n",
    "braggdisks.get_pointlist(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data in one of the PointLists\n",
    "braggdisks.get_pointlist(4,4).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing `DataObject` instances\n",
    "Saving information to a py4DSTEM file normally involves first saving the data as an instance of one of the `DataObject` child classes, then passing those to the `save` or `append` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data to save\n",
    "\n",
    "# Bright-field image\n",
    "x0,y0,R = 121,136,25\n",
    "py4DSTEM.visualize.show_circ(max_dp.data,0,2,center=(x0,y0),R=R,alpha=0.25,figsize=(6,6))\n",
    "BF_image_array = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,x0,y0,R)\n",
    "py4DSTEM.visualize.show(BF_image_array,contrast='minmax',figsize=(6,6))\n",
    "\n",
    "# Dark-field image\n",
    "x0,y0,R = 102,97,15\n",
    "py4DSTEM.visualize.show_circ(max_dp.data,0,2,center=(x0,y0),R=R,alpha=0.25,figsize=(6,6))\n",
    "DF_image_array = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,x0,y0,R)\n",
    "py4DSTEM.visualize.show(DF_image_array,contrast='minmax',figsize=(6,6))\n",
    "\n",
    "# Annular dark-field image\n",
    "x0,y0,Ri,Ro = 121,136,40,80\n",
    "py4DSTEM.visualize.show_annuli(max_dp.data,0,2,center=(x0,y0),Ri=Ri,Ro=Ro,alpha=0.25,figsize=(6,6))\n",
    "ADF_image_array = py4DSTEM.process.virtualimage.get_virtualimage_ann(datacube,x0,y0,Ri,Ro)\n",
    "py4DSTEM.visualize.show(ADF_image_array,contrast='minmax',figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a RealSlice\n",
    "BF_image_realslice = py4DSTEM.io.RealSlice(data=BF_image_array,name='BF_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_image_realslice.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a RealSlice with several 2D arrays\n",
    "images_realslice = py4DSTEM.io.RealSlice(\n",
    "                data=np.dstack([BF_image_array,DF_image_array,ADF_image_array]),\n",
    "                name='virtual_images',\n",
    "                slicelabels=['BF','DF','ADF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_realslice.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual 2D arrays can be accessed by slicing into the array directly\n",
    "DF_image_retrievedByIndex = images_realslice.data[:,:,1]\n",
    "\n",
    "py4DSTEM.visualize.show(DF_image_retrievedByIndex,contrast='minmax',figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual 2D arrays can also be accessed by name\n",
    "images_realslice.slicelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_image_retrievedByName = images_realslice.slices['DF']\n",
    "\n",
    "py4DSTEM.visualize.show(DF_image_retrievedByName,contrast='minmax',figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two arrays we just retrieved are the same...\n",
    "assert(np.sum(images_realslice.data[:,:,1]-images_realslice.slices['DF'])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution!\n",
    "# Note that RealSlice.slices (or DiffractionSlice.slices) points to 2D slices of RealSlice.data,\n",
    "# and should only be used to retrieve data, *not* to assign data.  Assignment of .slices will\n",
    "# not change the .data attribute, leading to inconsistencies - e.g.:\n",
    "\n",
    "#images_realslice.slices['DF'] = 0                            # Comment the next line and uncomment this one to break the assert statement\n",
    "images_realslice.slices['DF'] = images_realslice.data[:,:,1]  # Comment the previous line and uncomment this one to pass the assert statement\n",
    "assert(np.sum(images_realslice.data[:,:,1]-images_realslice.slices['DF'])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming dataobjects isn't strictly necessary, but is important - these are how\n",
    "# the datablock will be identified when saved to an .h5 file.\n",
    "images_realslice.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiffractionSlice has the same interface as RealSlice\n",
    "three_dps = py4DSTEM.io.DiffractionSlice(\n",
    "                 data=np.dstack([datacube.data[3,3+i,:,:] for i in range(3)]),\n",
    "                 slicelabels=['dp1','dp2','dp3'],\n",
    "                 name='three_dps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointList is intended to be flexible, enabling storage of N-points, each in M-dimensions.\n",
    "# As an example, let's save a length 500 array of 2D points representing the\n",
    "# functions x and cos(x)\n",
    "N = 500\n",
    "x = np.linspace(0,2*np.pi,N)\n",
    "coords = [('x',float),('cos(x)',float)]\n",
    "data = np.zeros(N,dtype=coords)              # Create a numpy structured array\n",
    "data['x'] = x                                # populate the array\n",
    "data['cos(x)'] = np.cos(x)\n",
    "cosine_curve = py4DSTEM.io.PointList(coordinates=coords,data=data,name='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(cosine_curve.data['x'],cosine_curve.data['cos(x)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountedDataCube, and PointListArrays are less likely to need to be generated\n",
    "# from scratch.  They may be outputs of py4DSTEM functions, e.g. fing_bragg_disks returns\n",
    "# a PointListArray of Bragg peak positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native files: save, append, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the files we'll save in this section already exist, remove them \n",
    "rm_file(filepath_py4DSTEM_1)\n",
    "rm_file(filepath_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a new file containing a single dataobject\n",
    "py4DSTEM.io.save(filepath_py4DSTEM_1, data=max_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append more dataobjects to this file\n",
    "py4DSTEM.io.append(filepath_py4DSTEM_1, data=BF_image)                       # We can append data one object at a time\n",
    "py4DSTEM.io.append(filepath_py4DSTEM_1, data=[three_dps,some_bragg_disks])   # or we can append a list of DataObjects all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we try to save a file where one already exists with the 'save' function\n",
    "# we'll get an error message\n",
    "py4DSTEM.io.save(filepath_py4DSTEM_1, data=[max_dp,BF_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're sure we don't need the old file, we can overwrite it using the 'overwrite' argument\n",
    "py4DSTEM.io.save(filepath_py4DSTEM_1, data=[max_dp,BF_image], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy a file\n",
    "py4DSTEM.io.copy(filepath_py4DSTEM_1,filepath_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native files: remove, overwrite, repack\n",
    "\n",
    "When removing or overwriting data blocks from an .h5 file, there's generally two options:\n",
    "\n",
    "1. remove the object from user space, such that the object no longer appears when we print the file contents, it's name is now free, and a new object of this name can be saved.  However, the disk space taken up by this object has not been freed, and is still taken up by this file.  This may be fine for some datablocks (i.e. a single 2D array) but less desireable for large data blocks.\n",
    "\n",
    "2. completly remove an object, such that the associated disk space is released, and the file size is accordingly reduced.  This requires re-writing all the *other* contents to a new file, then deleting the original file, therefore may be slow for larger files.\n",
    "\n",
    "When removing an object at index `n` from a file, option 1 is accomplished with\n",
    "\n",
    "```\n",
    "py4DSTEM.io.remove(filepath, data=n, delete=False)\n",
    "```\n",
    "and option 2 is accomplished with\n",
    "```\n",
    "py4DSTEM.io.remove(filepath, data=n)\n",
    "```\n",
    "which is equivalent to \n",
    "```\n",
    "py4DSTEM.io.remove(filepath, data=n)\n",
    "py4DSTEM.io.repack(filepath)\n",
    "```\n",
    "\n",
    "Note that `repack` will only save py4DSTEM DataObjects - so if you have an .h5 file that you've added custom blocks of data to, they'll be lost if you run `repack` on this file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up files\n",
    "rm_file(filepath_py4DSTEM_1)\n",
    "py4DSTEM.io.copy(filepath_py4DSTEM_sample,filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a 'hard' remove, i.e. option 2\n",
    "py4DSTEM.io.read(filepath_py4DSTEM_1)\n",
    "py4DSTEM.io.remove(filepath_py4DSTEM_1, data=1)\n",
    "py4DSTEM.io.read(filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwriting an object\n",
    "\n",
    "# Let's say we want to use a slightly large detector for our bright-field image\n",
    "# We could save a new object called BF_image_2, but that approach can get confusing quickly!\n",
    "# Instead, we'll overwrite the existing object called BF_image\n",
    "\n",
    "# Compute a new bright-field image\n",
    "x0,y0,R = 121,136,35\n",
    "py4DSTEM.visualize.show_circ(max_dp.data,0,2,center=(x0,y0),R=R,alpha=0.25,figsize=(6,6))\n",
    "BF_image_array_biggerDetector = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,x0,y0,R)\n",
    "py4DSTEM.visualize.show(BF_image_array,contrast='minmax',figsize=(6,6))\n",
    "\n",
    "# Make a new RealSlice.  Note that the 'name' field is the same as the old BF RealSlice\n",
    "BF_image_realslice_biggerDetector = py4DSTEM.io.RealSlice(data=BF_image_array_biggerDetector,name='BF_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we pass this to append, we'll get an error message signaling there's already an object with this name\n",
    "py4DSTEM.io.append(filepath_py4DSTEM_1, data=BF_image_realslice_biggerDetector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'soft' overwrite, i.e. which does not release the disk space, is accomplished with 'overwrite=1'\n",
    "# A 'hard' overwrite, i.e. which releases the disk space by re-writing the file, is accomplished with 'overwrite=2'\n",
    "# Using 'overwrite=2' is equivalent to using 'overwrite=1' followed by calling repack(filepath)\n",
    "py4DSTEM.io.append(filepath_py4DSTEM_1, data=BF_image_realslice, overwrite=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up files\n",
    "rm_file(filepath_py4DSTEM_1)\n",
    "rm_file(filepath_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading a non-native datacube, a Metadata instance is generated\n",
    "# and is attached as an attribute to the datacube\n",
    "datacube = py4DSTEM.io.read(filepath_dm)\n",
    "datacube.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metadata is organized into five dictionaries.  They are: \n",
    "# 'microscope', 'calibration', 'sample', 'user', 'comments'\n",
    "# They're reserved for the following uses:\n",
    "# 'microscope': everything from the raw / original file goes here.\n",
    "# 'calibration': all calibrations added later by the user go here.\n",
    "# 'sample': information about the sample and sample prep.\n",
    "# 'user': information about the microscope operator who acquired the data,\n",
    "#  as well as the user who performed the computational analysis.\n",
    "# 'comments': general use space for any other information\n",
    "datacube.metadata.dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata can be accessed directly from the dictionaries\n",
    "# or you can also get/set methods\n",
    "print(datacube.metadata.microscope['R_pixel_size'])\n",
    "print(datacube.metadata.get_R_pixel_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata should be assigned using the set methods\n",
    "datacube.metadata.set_R_pixel_size(2.0)\n",
    "datacube.metadata.set_R_pixel_size_units('nm')\n",
    "print(datacube.metadata.get_R_pixel_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some metadata items may exist in two places - 'microscope'\n",
    "# and 'calibration'.  For instance, this happens if the microscope had\n",
    "# some pixel calibrations, and then during data processing the user\n",
    "# re-performs more accurate calibrations.  When set_R_pixel_size was called\n",
    "# above, those were placed in 'calibration'.\n",
    "print(datacube.metadata.microscope)\n",
    "print(datacube.metadata.calibration)\n",
    "print('')\n",
    "print(datacube.metadata.microscope['R_pixel_size'])\n",
    "print(datacube.metadata.calibration['R_pixel_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get methods will default to returning the 'calibration' values\n",
    "# if they're present, and 'microscope' values if not.  Additional methods\n",
    "# exist to only retrieve these items from a specific dictionary.\n",
    "print(datacube.metadata.get_R_pixel_size())\n",
    "print(datacube.metadata.get_R_pixel_size__microscope())\n",
    "print(datacube.metadata.get_R_pixel_size__calibration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.metadata.get_Q_pixel_size())\n",
    "print(datacube.metadata.get_Q_pixel_size__microscope())\n",
    "print(datacube.metadata.get_Q_pixel_size__calibration()) # Should throw error - has not been set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach allows us to keep all the original metadata, while also\n",
    "# allowing for more refined calibrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time a datacube is saved to a new .h5 file, py4DSTEM checks to see if it has\n",
    "# a metadata instance attached.  If it does, it's saved to the .h5 file's metadata group\n",
    "py4DSTEM.io.save(filepath_py4DSTEM_1,datacube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata from the .h5 file\n",
    "metadata = py4DSTEM.io.read(filepath_py4DSTEM_1,metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.metadata.dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.get_R_pixel_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a new .h5 file which contains only the metadata\n",
    "py4DSTEM.io.save(filepath_py4DSTEM_2,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update an existing file's metadata with append\n",
    "metadata.set_R_pixel_size(10.0)\n",
    "py4DSTEM.io.append(filepath_py4DSTEM_2,metadata)\n",
    "print(py4DSTEM.io.read(filepath_py4DSTEM_2,metadata=True).get_R_pixel_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.io.read(filepath_py4DSTEM_2)      # TODO include metadata when printing file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `topgroup` and heirarchical formatting: .h5 files containing multiple py4DSTEM 'files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing two topgroups to a single .h5 file\n",
    "rm_file(filename_py4DSTEM_2)\n",
    "py4DSTEM.io.save(filename_py4DSTEM_2, topgroup='4DSTEM_dataset1', data=datacube)\n",
    "py4DSTEM.io.save(filename_py4DSTEM_2, topgroup='4DSTEM_dataset2', data=three_dps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading: if the file has multiple topgroups, print their names with read()\n",
    "py4DSTEM.io.read(filename_py4DSTEM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading: specifying a topgroup will list the contents of that subfile\n",
    "py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading: specifying a topgroup and a valid data_id retreives a DataObject\n",
    "data_from_topgroup = py4DSTEM.io.read(filename_py4DSTEM_2,\n",
    "                                      topgroup='4DSTEM_dataset2',\n",
    "                                      data_id='three_dps')\n",
    "data_from_topgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending: if the topgroup isn't specified, the topgroup names are printed\n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,data=BF_image_realslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending\n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,\n",
    "                   topgroup='4DSTEM_dataset2',\n",
    "                   data=BF_image_realslice)\n",
    "py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwriting with multiple topgroups\n",
    "# If there is an append conflict and the `overwrite` keyword is not specified,\n",
    "# an error message is printed and nothing is appended\n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,\n",
    "                   topgroup='4DSTEM_dataset2',\n",
    "                   data=BF_image_realslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this time overwriting objects in multi-topgroup files is possible only with overwrite=1 \n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,\n",
    "                   topgroup='4DSTEM_dataset2',\n",
    "                   data=BF_image_realslice,\n",
    "                   overwrite=1)\n",
    "py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite=2 fails \n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,\n",
    "                   topgroup='4DSTEM_dataset2',\n",
    "                   data=BF_image_realslice,\n",
    "                   overwrite=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, io.copy and io.repack are not yet supported for multi-topgroup files\n",
    "# Use them at your peril!\n",
    "# TODO: add assertions to prevent using these fns w/multi-tg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata and topgroups\n",
    "md1 = py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset1',metadata=True)\n",
    "md2 = py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2',metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a new piece of metadata to one of the topgroups and retrieve it again\n",
    "md1.set_Q_pixel_size(100)\n",
    "md2.set_Q_pixel_size(0.7)\n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,topgroup='4DSTEM_dataset1',data=md1)\n",
    "py4DSTEM.io.append(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2',data=md2)\n",
    "md3 = py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset1',metadata=True)\n",
    "md4 = py4DSTEM.io.read(filename_py4DSTEM_2,topgroup='4DSTEM_dataset2',metadata=True)\n",
    "print(md3.get_Q_pixel_size())\n",
    "print(md4.get_Q_pixel_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4dstem_dev",
   "language": "python",
   "name": "py4dstem_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
