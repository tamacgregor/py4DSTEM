{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#py4DSTEM-quickstart\" data-toc-modified-id=\"py4DSTEM-quickstart-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>py4DSTEM quickstart</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Version-info\" data-toc-modified-id=\"Version-info-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Version info</a></span></li></ul></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bragg-disk-detection\" data-toc-modified-id=\"Bragg-disk-detection-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Bragg disk detection</a></span></li><li><span><a href=\"#Save-and-load\" data-toc-modified-id=\"Save-and-load-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Save and load</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py4DSTEM quickstart\n",
    "---\n",
    "\n",
    "This jupyter notebook is meant as a quick intro to using py4DSTEM to write code to analyze 4DSTEM data.  In order, this notebook\n",
    "\n",
    "- loads data,\n",
    "- performs some initial visualizations, including virtual imaging and displaying diffraction data,\n",
    "- detects and visualizes bragg disk positions,\n",
    "- and saves outputs.\n",
    "\n",
    "This is by no means an exhuastive list of the package's capabilities.  An overview of various analyses is hereTKTK.\n",
    "\n",
    "### Data\n",
    "The 4DSTEM data was collected by Steven Zeltmann.\n",
    "\n",
    "To download the data, please [go here](https://drive.google.com/file/d/1B-xX3F65JcWzAg0v7f1aVwnawPIfb5_o/view?usp=sharing).  Assuming you're running the notebook on your local computer, you should then need to place the file somewhere on your filesystem, and in the cell immediately after this one, update the variable `filepath_input` to reflect that path to the file, then update `filepath_output` to set where you'll save the outputs.\n",
    "\n",
    "\n",
    "### Version info\n",
    "\n",
    "Last updated on 2019-11-25 with py4DSTEM version 0.11.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import py4DSTEM\n",
    "from file_getter import download_file_from_google_drive\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_input = \"data/small4DSTEMscan_10x10.dm3\"\n",
    "filepath_output = \"data/small4DSTEMscan_10x10_quickstart.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(filepath_input):\n",
    "    # Load a .dm3 file\n",
    "    datacube = py4DSTEM.io.read(filepath_input)\n",
    "    print('File Loaded')\n",
    "else:\n",
    "    print('Downloading File')\n",
    "    download_file_from_google_drive(id_='1B-xX3F65JcWzAg0v7f1aVwnawPIfb5_o',\n",
    "                                    destination=f'{filepath_input}')\n",
    "    \n",
    "    # Load a .dm3 file\n",
    "    datacube = py4DSTEM.io.read(filepath_input)\n",
    "    print('File Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file's metadata didn't contain the shape of the beam raster, so the data is reshaped to set that here\n",
    "datacube.set_scan_shape(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is shaped like\n",
    "# (x_R,y_R,x_K,y_K), where R/K are real/diffraction space\n",
    "datacube.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping and binning\n",
    "# Note that for large datasets, binning can also be performed during loading, for some fileformats.\n",
    "# See the docstring for io.read\n",
    "datacube.crop_data_real(2,10,2,10)\n",
    "datacube.bin_data_diffraction(2)        # If you get an error message here - welcome to Jupyter notebook problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum diffraction pattern\n",
    "# This is an computational fast and visually information rich way to slice into a 4D-STEM dataset.\n",
    "# Bragg scattering immediately pops out.  Here we can also clearly see the presence of diffraction shifts\n",
    "# in the shape of the bright central region.\n",
    "max_dp = np.max(datacube.data, axis=(0,1))\n",
    "py4DSTEM.visualize.show(max_dp,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position a bright-field detector\n",
    "x0,y0 = 121,136\n",
    "R = 25\n",
    "\n",
    "py4DSTEM.visualize.show_circ(max_dp,0,2,center=(x0,y0),R=R,alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the bright-field image\n",
    "BF_image = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,x0,y0,R)\n",
    "py4DSTEM.visualize.show(BF_image,contrast='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single diffraction pattern\n",
    "rx,ry = 2,5\n",
    "\n",
    "py4DSTEM.visualize.show_points(BF_image,rx,ry,contrast='minmax',figsize=(6,6))\n",
    "py4DSTEM.visualize.show(datacube.data[rx,ry,:,:],0,2,figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a grid of diffraction patterns\n",
    "x0,y0 = 3,1\n",
    "xL,yL = 3,3\n",
    "\n",
    "py4DSTEM.visualize.show_grid_overlay(BF_image,x0,y0,xL,yL,contrast='minmax',color='k',linewidth=5,figsize=(8,8))\n",
    "py4DSTEM.visualize.show_DP_grid(datacube,x0,y0,xL,yL,min=0,max=2,bordercolor='k',borderwidth=5,axsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bragg disk detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an image of the vacuum probe, to use as a template for finding the other Bragg disks\n",
    "# This step can look very different for different datasets - see TKTK probe_template_generation.ipynb\n",
    "# The best practice is to always record a vacuum probe of every camera length / convergence angle combo\n",
    "# you use in a day of experiments!\n",
    "probe = py4DSTEM.process.diskdetection.get_probe_from_vacuum_4Dscan(datacube)\n",
    "py4DSTEM.visualize.show(probe,0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the template matching step - see TKTK probe_template_generation.ipynb\n",
    "probe_kernel = py4DSTEM.process.diskdetection.get_probe_kernel_subtrgaussian(probe,sigma_probe_scale=2)\n",
    "py4DSTEM.visualize.show_kernel(probe_kernel,R=100,L=200,W=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few diffraction patterns to test parameters on\n",
    "# In most cases, (1) running disk detection on the full dataset will be slow, and (2) it can be helpful to \n",
    "# manually tune some the parameters for this algorithm. Here we're picking a few DP to tune on.\n",
    "rxs = 3,3,3\n",
    "rys = 0,4,7\n",
    "colors=['r','b','g']\n",
    "\n",
    "dp1 = datacube.data[rxs[0],rys[0],:,:]\n",
    "dp2 = datacube.data[rxs[1],rys[1],:,:]\n",
    "dp3 = datacube.data[rxs[2],rys[2],:,:]\n",
    "\n",
    "py4DSTEM.visualize.show_points(BF_image,contrast='minmax',x=rxs,y=rys,point_color=colors)\n",
    "py4DSTEM.visualize.show_image_grid(lambda i:[dp1,dp2,dp3][i],1,3,min=0.5,max=2,axsize=(5,5),\n",
    "                                   get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the disk detection on the selected DPs.  For more on disk detection, see TKTK disk_detection.ipynb\n",
    "corrPower=1\n",
    "sigma=2\n",
    "edgeBoundary=20\n",
    "minRelativeIntensity=0.005\n",
    "relativeToPeak=0\n",
    "minPeakSpacing=60\n",
    "maxNumPeaks=70\n",
    "subpixel='multicorr'\n",
    "upsample_factor=16\n",
    "\n",
    "disks_selected = py4DSTEM.process.diskdetection.find_Bragg_disks_selected(datacube,probe_kernel,rxs,rys,\n",
    "                        corrPower=corrPower,sigma=sigma,edgeBoundary=edgeBoundary,\n",
    "                        minRelativeIntensity=minRelativeIntensity,relativeToPeak=relativeToPeak,\n",
    "                        minPeakSpacing=minPeakSpacing,maxNumPeaks=maxNumPeaks,\n",
    "                        subpixel=subpixel,upsample_factor=upsample_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TKTK should I say something about the lambda functions???\n",
    "py4DSTEM.visualize.show_image_grid(lambda i:[dp1,dp2,dp3][i],1,3,min=0.5,max=2,axsize=(5,5),           # Show DPs\n",
    "                                   get_bc=lambda i:colors[i],\n",
    "                                   get_x=lambda i:disks_selected[i].data['qx'],\n",
    "                                   get_y=lambda i:disks_selected[i].data['qy'],\n",
    "                                   #get_s=lambda i:disks_selected[i].data['intensity'],\n",
    "                                   get_pointcolors=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run disk detection on the entire dataset\n",
    "disks = py4DSTEM.process.diskdetection.find_Bragg_disks(datacube,probe_kernel,\n",
    "                        corrPower=corrPower,sigma=sigma,edgeBoundary=edgeBoundary,\n",
    "                        minRelativeIntensity=minRelativeIntensity,relativeToPeak=relativeToPeak,\n",
    "                        minPeakSpacing=minPeakSpacing,maxNumPeaks=maxNumPeaks,\n",
    "                        subpixel=subpixel,upsample_factor=upsample_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and show the Bragg vector map.  See TKTK [what should I point to here?]\n",
    "braggvectormap = py4DSTEM.process.diskdetection.get_bragg_vector_map(disks,datacube.Q_Nx,datacube.Q_Ny)\n",
    "py4DSTEM.visualize.show(braggvectormap,0,2,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py4DSTEM saves data as DataObjects - there's six of them, and they are:\n",
    "# DataCubes, CountedDataCubes, DiffractionSlices, RealSlices, PointList, PointListArray\n",
    "max_dp_DiffSlice = py4DSTEM.io.DiffractionSlice(data=max_dp, name='max_dp')\n",
    "BF_image_RealSlice = py4DSTEM.io.RealSlice(data=BF_image, name='BF_image')\n",
    "three_dps = py4DSTEM.io.DiffractionSlice(data=np.dstack([dp1,dp2,dp3]),\n",
    "                                                         slicelabels=['dp1','dp2','dp3'],\n",
    "                                                         name='three_dps')\n",
    "dp3_disks = disks_selected[2]\n",
    "dp3_disks.name = 'some_bragg_disks'\n",
    "disks.name = 'braggpeaks'\n",
    "datacube.name = '4ddatacube'\n",
    "\n",
    "data = [max_dp_DiffSlice,BF_image_RealSlice,three_dps,dp3_disks,disks,datacube]\n",
    "py4DSTEM.io.save(filepath_output,data,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See TKTK io.ipynb for more on the fileformat and read/write functionality\n",
    "# For demo purposes, here we'll just open the file we just saved\n",
    "# When passed a native py4DSTEM file, the io.read function prints a list of the file contents\n",
    "py4DSTEM.io.read(filepath_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "max_dp_h5 = py4DSTEM.io.read(filepath_output,data_id='max_dp')\n",
    "max_dp_h5 = max_dp_h5.data\n",
    "\n",
    "datacube_h5 = py4DSTEM.io.read(filepath_output,data_id='4ddatacube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh look! Its the same data.  How nice.\n",
    "np.sum(max_dp_h5-max_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(datacube_h5.data - datacube.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4dstem_dev",
   "language": "python",
   "name": "py4dstem_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
